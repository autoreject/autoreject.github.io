{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Visualize bad sensors per trial\n\nThis example demonstrates how to use :mod:`autoreject` to\nvisualize the bad sensors in each trial\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: Mainak Jas <mainak.jas@telecom-paristech.fr>\n#         Denis A. Engemann <denis.engemann@gmail.com>\n# License: BSD-3-Clause\n\n# sphinx_gallery_thumbnail_number = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we download the data from OpenfMRI which is hosted on OpenNeuro.\nWe will do this using ``openneuro-py`` which can be installed using pip\n(``pip install openneuro-py``).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport openneuro\nimport autoreject\n\ndataset = 'ds000117'  # The id code on OpenNeuro for this example dataset\nsubject_id = 16  # OpenfMRI format of subject numbering\n\ntarget_dir = os.path.join(\n    os.path.dirname(autoreject.__file__), '..', 'examples', dataset)\nos.makedirs(target_dir, exist_ok=True)\n\nopenneuro.download(dataset=dataset, target_dir=target_dir,\n                   include=[f'sub-{subject_id}/ses-meg/'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will create epochs with data starting 200 ms before trigger onset\nand continuing up to 800 ms after that. The data contains visual stimuli for\nfamous faces, unfamiliar faces, as well as scrambled faces.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tmin, tmax = -0.2, 0.8\nevents_id = {'famous/first': 5, 'famous/immediate': 6, 'famous/long': 7}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us now load all the epochs into memory and concatenate them\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import mne  # noqa\n\nepochs = list()\nfor run in range(3, 7):\n    run_fname = os.path.join(target_dir, f'sub-{subject_id}', 'ses-meg', 'meg',\n                             f'sub-{subject_id}_ses-meg_task-facerecognition'\n                             '_run-{:02d}_meg.fif'.format(run))\n    raw = mne.io.read_raw_fif(run_fname, preload=True)\n    raw.pick_types(eeg=True, meg=False, stim=True)  # less memory + computation\n    raw.filter(1., 40., l_trans_bandwidth=0.5, n_jobs=1, verbose='INFO')\n\n    raw.set_channel_types({'EEG061': 'eog', 'EEG062': 'eog',\n                           'EEG063': 'ecg', 'EEG064': 'misc'})\n    raw.rename_channels({'EEG061': 'EOG061', 'EEG062': 'EOG062',\n                         'EEG063': 'ECG063', 'EEG064': 'MISC'})\n\n    events = mne.find_events(raw, stim_channel='STI101',\n                             consecutive='increasing',\n                             min_duration=0.003, verbose=True)\n    # Read epochs\n    mne.set_eeg_reference(raw)\n\n    epoch = mne.Epochs(raw, events, events_id, tmin, tmax, proj=True,\n                       baseline=None,\n                       preload=False, reject=None, decim=4)\n    epochs.append(epoch)\n\n    # Same `dev_head_t` for all runs so that we can concatenate them.\n    epoch.info['dev_head_t'] = epochs[0].info['dev_head_t']\n\n\nepochs = mne.epochs.concatenate_epochs(epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we apply autoreject\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from autoreject import AutoReject, compute_thresholds  # noqa\n\nthis_epoch = epochs['famous']\nexclude = []  # XXX\npicks = mne.pick_types(epochs.info, meg=False, eeg=True, stim=False,\n                       eog=False, exclude=exclude)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that :class:`autoreject.AutoReject` by design supports multiple\nchannels. If no picks are passed separate solutions will be computed for each\nchannel type and internally combines. This then readily supports cleaning\nunseen epochs from the different channel types used during fit.\nHere we only use a subset of channels to save time.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Also note that once the parameters are learned, any data can be repaired\nthat contains channels that were used during fit. This also means that time\nmay be saved by fitting :class:`autoreject.AutoReject` on a\nrepresentative subsample of the data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ar = AutoReject(picks=picks, random_state=42, n_jobs=1, verbose=True)\n\nepochs_ar, reject_log = ar.fit_transform(this_epoch, return_log=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can visualize the cross validation curve over two variables\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np  # noqa\nimport matplotlib.pyplot as plt  # noqa\nimport matplotlib.patches as patches  # noqa\nfrom autoreject import set_matplotlib_defaults  # noqa\n\nset_matplotlib_defaults(plt, style='default')\nloss = ar.loss_['eeg'].mean(axis=-1)  # losses are stored by channel type.\n\nplt.matshow(loss.T * 1e6, cmap=plt.get_cmap('viridis'))\nplt.xticks(range(len(ar.consensus)), ['%.1f' % c for c in ar.consensus])\nplt.yticks(range(len(ar.n_interpolate)), ar.n_interpolate)\n\n# Draw rectangle at location of best parameters\nax = plt.gca()\nidx, jdx = np.unravel_index(loss.argmin(), loss.shape)\nrect = patches.Rectangle((idx - 0.5, jdx - 0.5), 1, 1, linewidth=2,\n                         edgecolor='r', facecolor='none')\nax.add_patch(rect)\nax.xaxis.set_ticks_position('bottom')\nplt.xlabel(r'Consensus percentage $\\kappa$')\nplt.ylabel(r'Max sensors interpolated $\\rho$')\nplt.title('Mean cross validation error (x 1e6)')\nplt.colorbar()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "... and visualize the bad epochs and sensors. Bad sensors which have been\ninterpolated are in blue. Bad sensors which are not interpolated are in red.\nBad trials are also in red.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scalings = dict(eeg=40e-6)\nreject_log.plot_epochs(this_epoch, scalings=scalings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "... and the epochs after cleaning with autoreject\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "epochs_ar.plot(scalings=scalings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The epochs dropped by autoreject are also stored in epochs.drop_log\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "epochs_ar.plot_drop_log()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, the evoked before and after autoreject, for sanity check. We use\nthe ``spatial_colors`` argument from MNE as it allows us to see that\nthe eyeblinks have not yet been cleaned but the bad channels have been\nrepaired.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ylim = dict(eeg=(-15, 15))\nepochs.average().plot(ylim=ylim, spatial_colors=True)\nepochs_ar.average().plot(ylim=ylim, spatial_colors=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}