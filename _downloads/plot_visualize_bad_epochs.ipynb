{
  "nbformat_minor": 0, 
  "nbformat": 4, 
  "cells": [
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "%matplotlib inline"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "\n# Visualize bad sensors per trial\n\n\nThis example demonstrates how to use :mod:`autoreject` to\nvisualize the bad sensors in each trial\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "# Author: Mainak Jas <mainak.jas@telecom-paristech.fr>\n# License: BSD (3-clause)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "First, we download the data from OpenfMRI. We will download the tarfile,\nextract the necessary files and delete the tar from the disk\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "import os\nimport tarfile\n\nimport autoreject\nfrom autoreject.utils import fetch_file\n\nsubject_id = 16  # OpenfMRI format of subject numbering\n\nsrc_url = ('http://openfmri.s3.amazonaws.com/tarballs/'\n           'ds117_R0.1.1_sub016_raw.tgz')\nsubject = \"sub%03d\" % subject_id\n\nprint(\"processing subject: %s\" % subject)\nbase_path = os.path.join(os.path.dirname(autoreject.__file__), '..', 'examples')\ntarget = os.path.join(base_path, 'ds117_R0.1.1_sub016_raw.tgz')\nif not os.path.exists(os.path.join(base_path, 'ds117')):\n    if not os.path.exists(target):\n        fetch_file(src_url, target)\n    tf = tarfile.open(target)\n    print('Extracting files. This may take a while ...')\n    tf.extractall(path=base_path, members=tf.getmembers()[-25:-9:3])\n    os.remove(target)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "We will create epochs with data starting 200 ms before trigger onset\nand continuing up to 800 ms after that. The data contains visual stimuli for\nfamous faces, unfamiliar faces, as well as scrambled faces.\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "tmin, tmax = -0.2, 0.8\nevents_id = {'famous/first': 5, 'famous/immediate': 6, 'famous/long': 7}"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Let us now load all the epochs into memory and concatenate them\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "import mne\n\nepochs = list()\nfor run in range(3, 7):\n    run_fname = os.path.join(base_path, 'ds117', 'sub%03d' % subject_id, 'MEG',\n                             'run_%02d_raw.fif' % run)\n    raw = mne.io.read_raw_fif(run_fname, preload=True, add_eeg_ref=False)\n    mne.io.set_eeg_reference(raw, [])\n    raw.pick_types(eeg=True, meg=False, stim=True)  # less memory + computation\n    raw.filter(1, 40, l_trans_bandwidth=0.5, n_jobs=1, verbose='INFO')\n\n    raw.set_channel_types({'EEG061': 'eog', 'EEG062': 'eog',\n                           'EEG063': 'ecg', 'EEG064': 'misc'})\n    raw.rename_channels({'EEG061': 'EOG061', 'EEG062': 'EOG062',\n                         'EEG063': 'ECG063', 'EEG064': 'MISC'})\n\n    exclude = []  # XXX\n    picks = mne.pick_types(raw.info, meg=False, eeg=True, stim=False,\n                           eog=False, exclude=exclude)\n    events = mne.find_events(raw, stim_channel='STI101',\n                             consecutive='increasing',\n                             min_duration=0.003, verbose=True)\n    # Read epochs\n    epoch = mne.Epochs(raw, events, events_id, tmin, tmax, proj=True,\n                       add_eeg_ref=True, picks=picks, baseline=None,\n                       preload=False, reject=None, decim=4)\n    epochs.append(epoch)\n\n    # Same `dev_head_t` for all runs so that we can concatenate them.\n    epoch.info['dev_head_t'] = epochs[0].info['dev_head_t']\nepochs = mne.epochs.concatenate_epochs(epochs)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Now, we apply autoreject\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "from autoreject import LocalAutoRejectCV, compute_thresholds\nfrom functools import partial\n\nthis_epoch = epochs['famous']\nthresh_func = partial(compute_thresholds, random_state=42)\n\nar = LocalAutoRejectCV(thresh_func=thresh_func, verbose='tqdm')\nepochs_ar = ar.fit_transform(this_epoch.copy())"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "... and visualize the bad epochs and sensors. Bad sensors which have been\ninterpolated are in blue. Bad sensors which are not interpolated are in red.\nBad trials are also in red.\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "from autoreject import plot_epochs\nplot_epochs(this_epoch, bad_epochs_idx=ar.bad_epochs_idx,\n            fix_log=ar.fix_log, scalings=dict(eeg=40e-6),\n            title='')"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "... and the epochs after cleaning with autoreject\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "epochs_ar.plot(scalings=dict(eeg=40e-6))"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Finally, the evoked before and after autoreject, for sanity check. We use\nthe ``spatial_colors`` argument from MNE as it allows us to see that\nthe eyeblinks have not yet been cleaned but the bad channels have been\nrepaired.\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "ylim = dict(eeg=(-15, 15))\nepochs.average().plot(ylim=ylim, spatial_colors=True)\nepochs_ar.average().plot(ylim=ylim, spatial_colors=True)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2", 
      "name": "python2", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "2.7.12", 
      "pygments_lexer": "ipython2", 
      "codemirror_mode": {
        "version": 2, 
        "name": "ipython"
      }
    }
  }
}