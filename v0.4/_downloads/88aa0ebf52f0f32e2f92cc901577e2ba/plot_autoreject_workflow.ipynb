{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Preprocessing workflow with ``autoreject`` and ICA\nThis example demonstrates how to visualize data when preprocessing\nwith :mod:`autoreject` and discusses decisions about when and which\nother preprocessing steps to use in combination.\n\n**tldr**: We recommend that you first highpass filter the data,\nthen run autoreject (local) and supply the bad epochs detected by it\nto the ICA algorithm for a robust fit, and finally run\nautoreject (local) again.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: Alex Rockhill <aprockhill@mailbox.org>\n#         Mainak Jas <mjas@mgh.harvard.edu>\n#         Apoorva Karekal <apoorvak@uoregon.edu>\n#\n# License: BSD-3-Clause\n\n# sphinx_gallery_thumbnail_number = 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nFirst, we download resting-state EEG data from a Parkinson's patient\nfrom OpenNeuro. We will do this using ``openneuro-py`` which can be\ninstalled with the command ``pip install openneuro-py``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os.path as op\nimport matplotlib.pyplot as plt\nimport openneuro\n\nimport mne\nimport autoreject\n\ndataset = 'ds002778'  # The id code on OpenNeuro for this example dataset\nsubject_id = 'pd14'\n\ntarget_dir = op.join(op.dirname(autoreject.__file__), '..', 'examples')\nopenneuro.download(dataset=dataset, target_dir=target_dir,\n                   include=[f'sub-{subject_id}/ses-off'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will now load in the raw data from the bdf file downloaded from OpenNeuro\nand, since this is resting-state data without any events, make regularly\nspaced events with which to epoch the raw data. In the averaged plot,\nwe can see that there may be some eyeblink\nartifact contamination but, overall, the data is typical of\nresting-state EEG.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "raw_fname = op.join(target_dir, f'sub-{subject_id}',\n                    'ses-off', 'eeg', 'sub-pd14_ses-off_task-rest_eeg.bdf')\nraw = mne.io.read_raw_bdf(raw_fname, preload=True)\ndig_montage = mne.channels.make_standard_montage('biosemi32')\nraw.drop_channels([ch for ch in raw.ch_names\n                   if ch not in dig_montage.ch_names])\nraw.set_montage(dig_montage)  # use the standard montage\nepochs = mne.make_fixed_length_epochs(raw, duration=3, preload=True)\n\n# plot the data\nepochs.average().detrend().plot_joint()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Autoreject without any other preprocessing\nNow, we'll naively apply autoreject as our first preprocessing step.\n\nAs we can see in the plot of the rejected epochs, there are many eyeblinks\nthat caused the epoch to be dropped. This resulted in a lot of the data\nbeing lost.\n\nThe data looks fairly clean already and we don't want to interpolate\nmore than a few sensors since we only have 32 to start, so the\nnumber of channels to interpolate was set to check some low numbers\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ar = autoreject.AutoReject(n_interpolate=[1, 2, 3, 4], random_state=11,\n                           n_jobs=1, verbose=True)\nar.fit(epochs[:20])  # fit on a few epochs to save time\nepochs_ar, reject_log = ar.transform(epochs, return_log=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "visualize the dropped epochs\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "epochs[reject_log.bad_epochs].plot(scalings=dict(eeg=100e-6))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and the reject log\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "reject_log.plot('horizontal')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Autoreject with high-pass filter\nThe data may be very valuable and the time for the experiment\nlimited and so we may want to take steps to reduce the number of\nepochs dropped by first using other steps to preprocess the data.\nWe will use a high-pass filter first to remove slow drift that could\ncause epochs to be dropped.\n\nWhen making this decision to filter the data, we do want to be careful\nbecause filtering can spread sharp, high-frequency transients and\ndistort the phase of the signal. Most evoked response potential\nanalyses use filtering since the interest is in the time series, but\nif you are doing a frequency based analysis, filtering before the\nFourier transform could potentially be avoided by detrending instead.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "raw.filter(l_freq=1, h_freq=None)\nepochs = mne.make_fixed_length_epochs(raw, duration=3, preload=True)\nar = autoreject.AutoReject(n_interpolate=[1, 2, 3, 4], random_state=11,\n                           n_jobs=1, verbose=True)\nar.fit(epochs[:20])  # fit on a few epochs to save time\nepochs_ar, reject_log = ar.transform(epochs, return_log=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "visualize the dropped epochs\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "epochs[reject_log.bad_epochs].plot(scalings=dict(eeg=100e-6))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and the reject log. As we can see in the plot, high-pass filtering reduced\nthe number of epochs marked as bad by autoreject substantially.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "reject_log.plot('horizontal')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ICA\nFinally, we can apply independent components analysis (ICA) to remove\neyeblinks from the data. If our analysis were to be very dependent on\nsensors at the front of the head, we could skip ICA and use the previous\nresult. However, ICA can increase the amount of usable data by applying\na spatial filter that downscales the data in sensors most affected by\neyeblink artifacts.\n\nNote that ICA works best if bad segments of the data are removed\nHence, we will remove the bad segments from the\nprevious run of autoreject for the benefit of the ICA algorithm.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# compute ICA\nica = mne.preprocessing.ICA(random_state=99)\nica.fit(epochs[~reject_log.bad_epochs])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see in the plots below that ICA effectively removed eyeblink\nartifact.\n\nplot source components to see which is made up of blinks\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "exclude = [0,  # blinks\n           2  # saccades\n           ]\nica.plot_components(exclude)\nica.exclude = exclude"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "plot with and without eyeblink component\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ica.plot_overlay(epochs.average(), exclude=ica.exclude)\nica.apply(epochs, exclude=ica.exclude)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Autoreject with highpass filter and ICA\nWe can see in this section that preprocessing, especially ICA, can be made\nto do a lot of the heavy lifting. There isn't a huge difference when viewing\nthe averaged data because the ICA effectively limited the number\nof epochs that had to be dropped. However, there are still artifacts such as\nnon-stereotypical blinks that weren't able to be removed by ICA, channel\n\"pops\" (sharp transients with exponential RC decay), muscle artifact such as\njaw clenches and gross movement artifact that could still impact analyses.\n\nThese are the basic steps for a workflow with decisions that must be\nmade based on what the data is being used for. Following this may help\nyou optimize your use of ``autoreject`` in preprocessing.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# compute channel-level rejections\nar = autoreject.AutoReject(n_interpolate=[1, 2, 3, 4], random_state=11,\n                           n_jobs=1, verbose=True)\nar.fit(epochs[:20])  # fit on the first 20 epochs to save time\nepochs_ar, reject_log = ar.transform(epochs, return_log=True)\nepochs[reject_log.bad_epochs].plot(scalings=dict(eeg=100e-6))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will do a few more visualizations to see that removing the bad epochs\nfound by ``autoreject`` is still important even with preprocessing first.\nThis is especially important if your analyses include trial-level statistics\nsuch as looking for bursting activity. We'll visualize why autoreject\nexcluded these epochs and the effect that including these bad epochs would\nhave on the data.\n\nFirst, we will visualize the reject log\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "reject_log.plot('horizontal')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we will visualize the cleaned average data and compare it against\nthe bad segments.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "evoked_bad = epochs[reject_log.bad_epochs].average()\nplt.figure()\nplt.plot(evoked_bad.times, evoked_bad.data.T * 1e6, 'r', zorder=-1)\nepochs_ar.average().plot(axes=plt.gca())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As a last optional step, we can do inspect the reject_log and make manual\ncorrections to the reject_log. For instance, if data is limited, we may\nnot want to drop epochs but retain the list of bad epochs for quality\nassurance metrics.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "reject_log = ar.get_reject_log(epochs)\nbad_epochs = reject_log.bad_epochs.copy()\nreject_log.bad_epochs[:] = False  # no bad epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The modified reject log can be applied to the data as follows.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "epochs_ar = ar.transform(epochs, reject_log=reject_log)\nprint(f'Number of epochs originally: {len(epochs)}, '\n      f'after autoreject: {len(epochs_ar)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, don't forget that we are working with resting state data\nhere. Here we used long epochs of 3 seconds so that frequency-domain\nanalysis was possible with the epochs. However, this could also lead\nto longer segments of the data being rejected. If you want more\nfine-grained control over the artifacts, you can\nconstruct shorter epochs and use the autoreject log to mark\nannotations in MNE that can be used to reject the data during doing\ntime-frequency analysis. We want to emphasize that there\nis no subsitute for visual inspection. Irrespective of the rejection\nmethod used, we highly recommend users to inspect their preprocessed\ndata before further analyses.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}